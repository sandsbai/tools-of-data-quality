# 数据质量之真数不怕火炼 - TDD的重要基石 
![image](https://user-images.githubusercontent.com/20431533/120882615-931ca500-c60b-11eb-85e1-df13bcaed8d4.png)
>
>Talk is cheap, show me the data.

数据质量关乎数据产品的成败，这个事实似乎已不用强调。但是很多人并不清楚数据质量（DQ）的具体定义，似乎了解了数据质量的大概印象，却在如何识别数据质量问题和如何提升数据质量上束手无策。   

实际上，数据质量并没有一个绝对的、放之四海而皆准的数值标准，需要同时考虑客户需求和投入预算等因素。在这里，**数据质量的定义为：在满足用户需求上对数据完整性、准确性、一致性、易用性和实时性的最低要求。** 其中又以数据准确性方面问题最为常见和严峻，下面将以Data Warehouse设计开发过程中常见的问题和针对性的测试方案进行描述和讨论。   

## 1.Data Warehouse常见的数据准确性问题

当前的数据需求常以文档形式下发，本质是通过描述DW行为来约束开发者的开发产出（本质是Behavior Driven Design），但实际上不同开发者对行为的理解是不同的，这也是导致数据准确性低的重要原因。

除此之外，有原始错误的源数据表、描述不清的数据需求文档、有有缺陷的ETL代码、粗心的开发者也都是数据准确性问题的源头。小到字段名错误，大到数据逻辑错都是数据准确性的具体反映，下面详细列举一些常见的数据准确性问题，方便针对具体情况来来取有效方案。   

可将常见问题氛围结构和数据两类。   

### 1.1.结构错误   
#### 1.1.1.表字段拼写和描述错误
表字段和描述内容是数据用户了解数据信息的重要入口，错误的拼写错误和描述错误，不仅会让用户误用数据，甚至还会让用户对数据的准确性和权威性存疑。  

#### 1.1.2.表字段类型错误
表的用户可能是下一级ETL开发者，也可能是BI开发者，错误的表字段类型错误同样会影响下游使用。譬如int32类型被错误标记为float64，那么会出现筛选范围限制过大或过小的情况。

### 1.2.列数据错误
有时候仅对表结构信息进行验证是不够的。ETL代码的错误，会导致数据的错误合成和转换，反映在数据上就是出现异常的空值、唯一值和范围错误等。此处之所以写**列数据错误**，而不用**数据错误**等其他范围更广的概念，是因为跨列的数据错误形成原因更复杂且解决方案更复杂，留待后面再继续介绍。但是，仅对数据内容进行表字段类型和列数据错误的识别和纠正，就已经能纠正数据开发工作中的大部分问题，因此也是有现实价值的。     

#### 1.2.1.空值错误   
所谓的空值错误，就是依据设计初衷，某字段不可能出现空值的情况。如主键字段、房屋带看时间字段或者经纪人所在门店编码等。这些字段一旦出现空值，则需要进行预警和讨论。当然，在业务系统侧由于人工误操作等原因，可能会出现少量行出现字段为空的情况，但具体问题应具体分析，出现空值预警尽是为了提醒DPM或者开发者注意，避免其他重大问题。  

空值错误的衡量指标可为空值数(na_count)和空值率(na_ratio)，其中控制率为该列数据中值为空、文本null或者其他可表示为空值的符号的总数量，而空值率（na_ratio）=na_count/total_count。
 
#### 1.2.2.唯一值错误   
所谓唯一值错误，就是某字段或者组合字段作为主键，每个值必然是唯一的。同时唯一值错误还可拓展为占比异常错误，例如某类房产业务中，A品牌和B品牌的占比一直为3:2左右，某天突然变动为2:3，必然是由于业务变动或者其他原因导致的。

唯一值错误的衡量指标为唯一值数量（unique_count）和唯一值占比(unique_ratio), 其中唯一值数量为所有列值的去重集合的数量，而唯一值占比（unique_ratio）=unique_count/totol_count。

#### 1.2.3.范围错误
所谓范围值错误，就是列值超出了正常的列值范围。例如表示岁数的列出现了200岁的异常例子，又或者房屋带看日期出现了2025-01-01年的情况，这些都是违反常识的。当然针对不同的数据类型，范围类型可分为不同情况，具体如下：
* 日期类型范围   
如果字段为日期类型，则日期的类型范围为（2018-01-01，2021-06-05），凡超出了该时间范围的都是离群点。

* 数值类型范围   
如果字段为数值类型，如int64或者float64等，则数值的范围为（352，723615），凡超出了该数值范围的都是离群点。

* 字符类型范围   
如果字段为字符类型，则字符的范围为（2，19），凡超出了该字符长度范围的都是离群点。

* 枚举类型范围   
枚举值范围同时对日期、数值和字符类型的字段都有效，只要这些字段的取值范围是预定义且有限的。例如，经纪人的品牌类型就是有限的，凡突然出现了新的品牌枚举值，就需要从业务变动或者ETL错误方面去分析原因。   
 
## 2.针对数据准确性问题的解决方案  
明确了常见问题类别，我们可以提出各种各样的解决方案，包括流程的建设，人员职责的划分和工具的使用等。实际上，很多公司在数据产品运维阶段或者产品上线前都会有较为完整的数据测试方案，这些方案也大多能解决上述提到的数据质量问题。但是不排除有些公司，或者在一些细小环节上并没有建立起完整的测试方案，因此我们需要根据对数据问题的理解，来自行搭建小型的数据质量测试环境。尤其是对承担繁重的数据测试任务的DPM来说，使用一套高效而精准的数据质量测试工具，对日常数据产品的管理尤为重要。 

市面上已经有很多精巧的数据质量测试工具（后续会对这些工具做一次竞品分析），但是这些工具往往过于复杂且收费昂贵，且对于小场景的数据测试也是杀鸡用牛刀。下面推荐两个简单、便宜（免费）的方案，一个是老少咸宜的Excel，另一个则是需要一定Python编程基础（后续会将相关的Python代码发布）。

### 2.1.基于Excel的测试方案   
将数据从数据仓库中导出为Excel后，可使用筛选器或者数据透视表对数据内容进行一系列检查。通过使用数据透视图，可对表结构字段进行检查，对表字段类型进行推测，对某列的值集合进行查看和筛选，方便查看是否存在空值、唯一值的数量以及取值范围等等。更进一步的，通过筛选器的条件选择来模拟BI工具，还可以测试数据表是否能满足数据需求。关于Excel的数据透视表的使用方法，可以[参考书本](https://github.com/sandsbai/tools-of-data-quality/blob/main/Bill%20Jelen%2C%20Michael%20Alexander%20-%20Excel%202016%20Pivot%20table%20data%20crunching-Que%20(2016).pdf)，在此不再赘述。   

但是由于Excel涉及人工操作的环节较多，易出错，效率方面还存在进一步优化的空间，下面就介绍基于Python脚本的测试方案。

### 2.2.基于Python脚本的TDD方案      
基于Python3.0和专业的数据处理库pandas，可对数据更快捷和智能的数据质量分析。

#### 2.1.1.检测项配置   
针对上面章节中提到的每一类问题的自动化检测，都需预设置明确的阈值范围或者标准。例如表字段名称的标准值是什么，表字段类型的标准值是什么，哪一列是强制非空，哪一列又是唯一值要达到80%以上，又有哪一列的数据范围应该在多少以内，等等，这些都称之为检测项的配置。   

显然，不同的表的检测配置项是不一样的，甚至还会不断更新和演进，因此有必要维护检测项的配置库，方便后期对表的重复检测。而作为TDD理念的重要组成部分，检测项配置的最佳时机，应该是在创建数据需求的同时完成，明确的定义了开发者需要交付的数据质量等级。

具体的配置项格式，可采用[Python的config file格式](https://docs.python.org/3/library/configparser.html)。


#### 2.1.2.预处理和检测
使用pandas，可以很方便对表的每一列进行单独处理。具体的API介绍详见[在线文档](https://pandas.pydata.org/)。
* **数据文件导入**  
pandas具有读入Excel文档或者csv等多种数据文档的能力，具体[详见文档](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html)。
* **数据预处理和空值检测**  
pandas可对列进行空值数量统计，并通过dropna函数来剔除所有空值。剔除空值的操作非常关键，因为空值会列数据类型检测等后续的一系列数据分析工作产生准确度的影响。
* **唯一值检测**
在剔除空值之后，pandas可对列值进行唯一值数量进行统计，对超出唯一值占比范围的列进行识别和记录。
* **范围检测** 
在识别列数据的数据类习惯后，针对不同的数据类型进行范围检测，对超出配置项范围的离群值进行识别和记录。     
* **其他检测**   
pandas的功能较为强大，除了以上列举的功能像之外，还有其他更为强大的数据分析功能可以使用。具体有待数据需求的提出。   

#### 2.2.3.检测报告生成
单纯的数据质量分析是没有意义的，在进行数据质量分析之前，我们就需要明确了目的：用户提交的数据需求是否能够被满足。   
因此最后需要根据量化的各项检测结果，检测揭露的问题，连同检测是否通过的定性结论一同记录在检测报告上。很显然，检测是否通过的最重要判断原则，就是数据本身的数据质量是否满足数据需求。   
一个较为完整的检测报告至少需要包含以下几项内容：      
* 被检测表名   
* 被检测表数据版本和时间分区   
* 被检测数据的总行数   
* 表结构检测结果、问题和解释   
* 列数据检测结果、问题和解释      
* 通过结论




